#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æ¡£ç‰ˆæœ¬ç®¡ç†è„šæœ¬ (Python ç‰ˆæœ¬)
å®ç°æ–‡æ¡£ç‰ˆæœ¬æ ‡è¯†å’Œæ›´æ–°æé†’ï¼Œè¿½è¸ªæ–‡æ¡£å˜æ›´
"""

import os
import sys
import json
import hashlib
import argparse
import subprocess
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import yaml


class DocumentVersion:
    """æ–‡æ¡£ç‰ˆæœ¬ä¿¡æ¯ç±»"""
    
    def __init__(self, file_path: str, version: str, last_modified: str, content_hash: str):
        self.file_path = file_path
        self.version = version
        self.last_modified = last_modified
        self.content_hash = content_hash
        self.git_commit = ""
        self.author = ""
        self.change_summary = ""
        self.dependencies = []
    
    def to_dict(self) -> dict:
        return {
            'FilePath': self.file_path,
            'Version': self.version,
            'LastModified': self.last_modified,
            'ContentHash': self.content_hash,
            'GitCommit': self.git_commit,
            'Author': self.author,
            'ChangeSummary': self.change_summary,
            'Dependencies': self.dependencies
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'DocumentVersion':
        version = cls(
            data.get('FilePath', ''),
            data.get('Version', ''),
            data.get('LastModified', ''),
            data.get('ContentHash', '')
        )
        version.git_commit = data.get('GitCommit', '')
        version.author = data.get('Author', '')
        version.change_summary = data.get('ChangeSummary', '')
        version.dependencies = data.get('Dependencies', [])
        return version


class VersionChange:
    """ç‰ˆæœ¬å˜æ›´ä¿¡æ¯ç±»"""
    
    def __init__(self, file_path: str, old_version: str, new_version: str, 
                 change_type: str, timestamp: str):
        self.file_path = file_path
        self.old_version = old_version
        self.new_version = new_version
        self.change_type = change_type
        self.timestamp = timestamp
        self.description = ""
    
    def to_dict(self) -> dict:
        return {
            'FilePath': self.file_path,
            'OldVersion': self.old_version,
            'NewVersion': self.new_version,
            'ChangeType': self.change_type,
            'Timestamp': self.timestamp,
            'Description': self.description
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'VersionChange':
        change = cls(
            data.get('FilePath', ''),
            data.get('OldVersion', ''),
            data.get('NewVersion', ''),
            data.get('ChangeType', ''),
            data.get('Timestamp', '')
        )
        change.description = data.get('Description', '')
        return change


class DocumentVersionManager:
    """æ–‡æ¡£ç‰ˆæœ¬ç®¡ç†å™¨ç±»"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root).resolve()
        self.version_file = self.project_root / '.kiro' / 'docs-versions.json'
        self.config_file = self.project_root / '.kiro' / 'docs-version-config.yml'
        self.versions: Dict[str, DocumentVersion] = {}
        self.changes: List[VersionChange] = []
        
        # ç¡®ä¿ç‰ˆæœ¬æ–‡ä»¶ç›®å½•å­˜åœ¨
        self.version_file.parent.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½ç°æœ‰ç‰ˆæœ¬ä¿¡æ¯
        self.load_versions()
        self.load_config()
    
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        self.config = {
            'version_management': {
                'version_format': 'semantic',
                'auto_increment': {
                    'major': ['breaking_change', 'api_change', 'major_restructure'],
                    'minor': ['new_section', 'new_feature_doc', 'significant_update'],
                    'patch': ['content_update', 'typo_fix', 'format_change', 'link_update']
                }
            },
            'document_scanning': {
                'include_patterns': ['docs/**/*.md', 'README*.md', '*.md'],
                'exclude_patterns': ['node_modules/**', '.git/**', 'target/**', 'build/**']
            },
            'version_headers': {
                'enabled': True,
                'template': '''<!-- ç‰ˆæœ¬ä¿¡æ¯ -->
> **æ–‡æ¡£ç‰ˆæœ¬**: {version}  
> **æœ€åæ›´æ–°**: {last_modified}  
> **Git æäº¤**: {git_commit}  
> **ä½œè€…**: {author}
<!-- /ç‰ˆæœ¬ä¿¡æ¯ -->''',
                'position': 'after_title'
            },
            'outdated_detection': {
                'default_threshold_days': 30
            }
        }
        
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    loaded_config = yaml.safe_load(f)
                    if loaded_config:
                        self._merge_config(self.config, loaded_config)
            except Exception as e:
                print(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
    
    def _merge_config(self, base: dict, update: dict):
        """é€’å½’åˆå¹¶é…ç½®"""
        for key, value in update.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                self._merge_config(base[key], value)
            else:
                base[key] = value
    
    def load_versions(self):
        """åŠ è½½ç‰ˆæœ¬ä¿¡æ¯"""
        if not self.version_file.exists():
            return
        
        try:
            with open(self.version_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.versions = {}
            if 'versions' in data:
                for file_path, version_data in data['versions'].items():
                    self.versions[file_path] = DocumentVersion.from_dict(version_data)
            
            self.changes = []
            if 'changes' in data:
                for change_data in data['changes']:
                    self.changes.append(VersionChange.from_dict(change_data))
        
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")
            self.versions = {}
            self.changes = []
    
    def save_versions(self):
        """ä¿å­˜ç‰ˆæœ¬ä¿¡æ¯"""
        try:
            data = {
                'versions': {path: version.to_dict() for path, version in self.versions.items()},
                'changes': [change.to_dict() for change in self.changes],
                'last_updated': datetime.now().isoformat()
            }
            
            with open(self.version_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        
        except Exception as e:
            print(f"âŒ ä¿å­˜ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")
    
    def calculate_content_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶å†…å®¹å“ˆå¸Œ"""
        try:
            full_path = self.project_root / file_path
            if full_path.exists():
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                return hashlib.sha256(content.encode('utf-8')).hexdigest()[:16]
        except Exception:
            pass
        return ""
    
    def get_git_info(self, file_path: str) -> Tuple[str, str]:
        """è·å– Git ä¿¡æ¯"""
        try:
            full_path = self.project_root / file_path
            result = subprocess.run(
                ['git', 'log', '-1', '--format=%H|%an', '--', str(full_path)],
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.returncode == 0 and result.stdout.strip():
                parts = result.stdout.strip().split('|', 1)
                commit = parts[0][:8] if parts else ""
                author = parts[1] if len(parts) > 1 else ""
                return commit, author
        except Exception:
            pass
        return "", ""
    
    def generate_version_number(self, file_path: str, content_hash: str) -> str:
        """ç”Ÿæˆç‰ˆæœ¬å·"""
        existing_version = self.versions.get(file_path)
        
        if not existing_version:
            return "1.0.0"
        
        if existing_version.content_hash == content_hash:
            return existing_version.version
        
        # å†…å®¹æœ‰å˜åŒ–ï¼Œé€’å¢ç‰ˆæœ¬å·
        try:
            parts = existing_version.version.split('.')
            if len(parts) == 3:
                major, minor, patch = map(int, parts)
                patch += 1  # ç®€å•çš„ç‰ˆæœ¬é€’å¢ç­–ç•¥
                return f"{major}.{minor}.{patch}"
        except ValueError:
            pass
        
        return "1.0.0"
    
    def detect_document_dependencies(self, file_path: str) -> List[str]:
        """æ£€æµ‹æ–‡æ¡£ä¾èµ–å…³ç³»"""
        dependencies = []
        
        try:
            full_path = self.project_root / file_path
            if not full_path.exists():
                return dependencies
            
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æµ‹ Markdown é“¾æ¥
            md_links = re.findall(r'\[.*?\]\(([^)]+)\)', content)
            for link in md_links:
                if not link.startswith(('http://', 'https://', 'mailto:')) and link.endswith('.md'):
                    dep_path = (full_path.parent / link).resolve()
                    if dep_path.exists():
                        rel_path = dep_path.relative_to(self.project_root)
                        dependencies.append(str(rel_path).replace('\\', '/'))
            
            # æ£€æµ‹æ–‡ä»¶å¼•ç”¨ #[[file:...]]
            file_refs = re.findall(r'#\[\[file:([^\]]+)\]\]', content)
            for ref in file_refs:
                ref_path = self.project_root / ref
                if ref_path.exists():
                    dependencies.append(ref)
        
        except Exception as e:
            print(f"âš ï¸ æ£€æµ‹ä¾èµ–å…³ç³»å¤±è´¥ {file_path}: {e}")
        
        return sorted(set(dependencies))
    
    def scan_documents(self) -> List[str]:
        """æ‰«ææ–‡æ¡£æ–‡ä»¶"""
        documents = []
        
        include_patterns = self.config['document_scanning']['include_patterns']
        exclude_patterns = self.config['document_scanning']['exclude_patterns']
        
        for pattern in include_patterns:
            try:
                if '**' in pattern:
                    # é€’å½’æœç´¢
                    base_path = pattern.split('**')[0].rstrip('/')
                    full_base_path = self.project_root / base_path if base_path else self.project_root
                    
                    if full_base_path.exists():
                        for md_file in full_base_path.rglob('*.md'):
                            rel_path = md_file.relative_to(self.project_root)
                            rel_path_str = str(rel_path).replace('\\', '/')
                            
                            # æ£€æŸ¥æ’é™¤æ¨¡å¼
                            excluded = False
                            for exclude_pattern in exclude_patterns:
                                if self._match_pattern(rel_path_str, exclude_pattern):
                                    excluded = True
                                    break
                            
                            if not excluded:
                                documents.append(rel_path_str)
                else:
                    # ç®€å•æ¨¡å¼åŒ¹é…
                    for md_file in self.project_root.glob(pattern):
                        if md_file.is_file():
                            rel_path = md_file.relative_to(self.project_root)
                            rel_path_str = str(rel_path).replace('\\', '/')
                            
                            # æ£€æŸ¥æ’é™¤æ¨¡å¼
                            excluded = False
                            for exclude_pattern in exclude_patterns:
                                if self._match_pattern(rel_path_str, exclude_pattern):
                                    excluded = True
                                    break
                            
                            if not excluded:
                                documents.append(rel_path_str)
            
            except Exception as e:
                print(f"âš ï¸ æ‰«ææ¨¡å¼å¤±è´¥ {pattern}: {e}")
        
        return sorted(set(documents))
    
    def _match_pattern(self, path: str, pattern: str) -> bool:
        """ç®€å•çš„æ¨¡å¼åŒ¹é…"""
        if '**' in pattern:
            parts = pattern.split('**')
            if len(parts) == 2:
                prefix, suffix = parts
                return path.startswith(prefix.rstrip('/')) and path.endswith(suffix.lstrip('/'))
        elif '*' in pattern:
            # ç®€å•çš„é€šé…ç¬¦åŒ¹é…
            import fnmatch
            return fnmatch.fnmatch(path, pattern)
        else:
            return path == pattern
    
    def update_document_version(self, file_path: str) -> Optional[VersionChange]:
        """æ›´æ–°æ–‡æ¡£ç‰ˆæœ¬"""
        full_path = self.project_root / file_path
        
        if not full_path.exists():
            # æ–‡æ¡£è¢«åˆ é™¤
            if file_path in self.versions:
                old_version = self.versions[file_path].version
                del self.versions[file_path]
                
                change = VersionChange(
                    file_path, old_version, "", "DELETED",
                    datetime.now().isoformat()
                )
                change.description = "æ–‡æ¡£å·²åˆ é™¤"
                self.changes.append(change)
                return change
            return None
        
        # è®¡ç®—å½“å‰æ–‡æ¡£ä¿¡æ¯
        content_hash = self.calculate_content_hash(file_path)
        git_commit, author = self.get_git_info(file_path)
        dependencies = self.detect_document_dependencies(file_path)
        
        # ç”Ÿæˆç‰ˆæœ¬å·
        new_version = self.generate_version_number(file_path, content_hash)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
        existing_version = self.versions.get(file_path)
        
        if existing_version:
            if existing_version.content_hash == content_hash:
                # å†…å®¹æœªå˜åŒ–ï¼Œä½†å¯èƒ½éœ€è¦æ›´æ–°å…¶ä»–ä¿¡æ¯
                existing_version.git_commit = git_commit
                existing_version.author = author
                existing_version.dependencies = dependencies
                return None
            
            # å†…å®¹æœ‰å˜åŒ–
            change_type = "MODIFIED"
            old_version = existing_version.version
        else:
            # æ–°æ–‡æ¡£
            change_type = "CREATED"
            old_version = ""
        
        # æ›´æ–°ç‰ˆæœ¬ä¿¡æ¯
        version = DocumentVersion(
            file_path, new_version, datetime.now().isoformat(), content_hash
        )
        version.git_commit = git_commit
        version.author = author
        version.dependencies = dependencies
        
        self.versions[file_path] = version
        
        # è®°å½•å˜æ›´
        change = VersionChange(
            file_path, old_version, new_version, change_type,
            datetime.now().isoformat()
        )
        change.description = f"æ–‡æ¡£{change_type.lower()}"
        self.changes.append(change)
        
        return change
    
    def update_all_versions(self) -> List[VersionChange]:
        """æ›´æ–°æ‰€æœ‰ç‰ˆæœ¬"""
        print("ğŸ” æ‰«ææ–‡æ¡£æ–‡ä»¶...")
        documents = self.scan_documents()
        
        print(f"ğŸ“„ å‘ç° {len(documents)} ä¸ªæ–‡æ¡£æ–‡ä»¶")
        
        all_changes = []
        
        for doc_path in documents:
            change = self.update_document_version(doc_path)
            if change:
                all_changes.append(change)
                print(f"  ğŸ“ {change.change_type}: {change.file_path} ({change.old_version} â†’ {change.new_version})")
        
        # æ£€æŸ¥å·²åˆ é™¤çš„æ–‡æ¡£
        existing_paths = set(documents)
        to_remove = [path for path in self.versions.keys() if path not in existing_paths]
        
        for file_path in to_remove:
            change = self.update_document_version(file_path)
            if change:
                all_changes.append(change)
                print(f"  ğŸ—‘ï¸ {change.change_type}: {change.file_path}")
        
        return all_changes
    
    def check_outdated_documents(self, days_threshold: int) -> List[str]:
        """æ£€æŸ¥è¿‡æœŸæ–‡æ¡£"""
        outdated = []
        threshold_date = datetime.now() - timedelta(days=days_threshold)
        
        for file_path, version in self.versions.items():
            try:
                last_modified = datetime.fromisoformat(version.last_modified.replace('Z', '+00:00'))
                if last_modified < threshold_date:
                    outdated.append(file_path)
            except ValueError:
                # æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè®¤ä¸ºæ˜¯è¿‡æœŸçš„
                outdated.append(file_path)
        
        return outdated
    
    def add_version_headers(self) -> int:
        """æ·»åŠ ç‰ˆæœ¬å¤´ä¿¡æ¯"""
        if not self.config['version_headers']['enabled']:
            return 0
        
        added_count = 0
        template = self.config['version_headers']['template']
        position = self.config['version_headers']['position']
        
        for file_path, version_info in self.versions.items():
            full_path = self.project_root / file_path
            
            if not full_path.exists():
                continue
            
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç”Ÿæˆç‰ˆæœ¬å¤´
                version_header = template.format(
                    version=version_info.version,
                    last_modified=version_info.last_modified[:10],
                    git_commit=version_info.git_commit,
                    author=version_info.author
                )
                
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç‰ˆæœ¬å¤´
                if '<!-- ç‰ˆæœ¬ä¿¡æ¯ -->' in content:
                    # æ›´æ–°ç°æœ‰ç‰ˆæœ¬å¤´
                    new_content = re.sub(
                        r'<!-- ç‰ˆæœ¬ä¿¡æ¯ -->.*?<!-- /ç‰ˆæœ¬ä¿¡æ¯ -->',
                        version_header,
                        content,
                        flags=re.DOTALL
                    )
                    
                    if new_content != content:
                        with open(full_path, 'w', encoding='utf-8') as f:
                            f.write(new_content)
                        added_count += 1
                else:
                    # æ·»åŠ æ–°ç‰ˆæœ¬å¤´
                    if position == 'after_title':
                        # åœ¨ç¬¬ä¸€ä¸ªæ ‡é¢˜åæ’å…¥
                        lines = content.split('\n')
                        title_index = -1
                        for i, line in enumerate(lines):
                            if line.startswith('# '):
                                title_index = i
                                break
                        
                        if title_index >= 0:
                            new_lines = (
                                lines[:title_index + 1] +
                                ['', version_header, ''] +
                                lines[title_index + 1:]
                            )
                            new_content = '\n'.join(new_lines)
                            
                            with open(full_path, 'w', encoding='utf-8') as f:
                                f.write(new_content)
                            added_count += 1
                    elif position == 'top':
                        # åœ¨æ–‡æ¡£é¡¶éƒ¨æ’å…¥
                        new_content = version_header + '\n\n' + content
                        with open(full_path, 'w', encoding='utf-8') as f:
                            f.write(new_content)
                        added_count += 1
            
            except Exception as e:
                print(f"âš ï¸ æ·»åŠ ç‰ˆæœ¬å¤´å¤±è´¥ {file_path}: {e}")
        
        return added_count
    
    def export_version_data(self, export_path: str):
        """å¯¼å‡ºç‰ˆæœ¬æ•°æ®"""
        try:
            export_data = {
                'metadata': {
                    'export_time': datetime.now().isoformat(),
                    'project_root': str(self.project_root),
                    'total_documents': len(self.versions),
                    'total_changes': len(self.changes)
                },
                'versions': {path: version.to_dict() for path, version in self.versions.items()},
                'changes': [change.to_dict() for change in self.changes],
                'statistics': {
                    'by_type': {},
                    'by_month': {},
                    'outdated_count': len(self.check_outdated_documents(30))
                }
            }
            
            # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
            from collections import Counter
            
            change_types = Counter(change.change_type for change in self.changes)
            export_data['statistics']['by_type'] = dict(change_types)
            
            change_months = Counter()
            for change in self.changes:
                try:
                    month = datetime.fromisoformat(change.timestamp.replace('Z', '+00:00')).strftime('%Y-%m')
                    change_months[month] += 1
                except ValueError:
                    change_months['unknown'] += 1
            export_data['statistics']['by_month'] = dict(change_months)
            
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šå¯¼å‡ºæ ¼å¼
            export_path_obj = Path(export_path)
            
            if export_path_obj.suffix.lower() == '.json':
                with open(export_path, 'w', encoding='utf-8') as f:
                    json.dump(export_data, f, ensure_ascii=False, indent=2)
            elif export_path_obj.suffix.lower() == '.csv':
                import csv
                with open(export_path, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(['FilePath', 'Version', 'LastModified', 'GitCommit', 'Author'])
                    for path, version in self.versions.items():
                        writer.writerow([
                            path, version.version, version.last_modified,
                            version.git_commit, version.author
                        ])
            else:
                # é»˜è®¤å¯¼å‡ºä¸º JSON
                with open(export_path, 'w', encoding='utf-8') as f:
                    json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        except Exception as e:
            print(f"âŒ å¯¼å‡ºç‰ˆæœ¬æ•°æ®å¤±è´¥: {e}")
    
    def generate_version_report(self) -> str:
        """ç”Ÿæˆç‰ˆæœ¬æŠ¥å‘Š"""
        report = ["# æ–‡æ¡£ç‰ˆæœ¬ç®¡ç†æŠ¥å‘Š\n"]
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_docs = len(self.versions)
        recent_changes = [
            change for change in self.changes
            if self._is_recent_change(change.timestamp, 7)
        ]
        
        report.extend([
            "## ç‰ˆæœ¬ç»Ÿè®¡\n",
            f"- æ€»æ–‡æ¡£æ•°: {total_docs}",
            f"- è¿‘7å¤©å˜æ›´: {len(recent_changes)}",
            f"- ç‰ˆæœ¬æ–‡ä»¶: {self.version_file}",
            f"- æœ€åæ‰«æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        ])
        
        # æœ€è¿‘å˜æ›´
        if recent_changes:
            report.extend(["## æœ€è¿‘å˜æ›´\n"])
            for change in sorted(recent_changes, key=lambda x: x.timestamp, reverse=True)[:10]:
                timestamp = change.timestamp[:10]
                report.append(
                    f"- **{change.change_type}**: {change.file_path} "
                    f"({change.old_version} â†’ {change.new_version}) - {timestamp}"
                )
            report.append("")
        
        # è¿‡æœŸæ–‡æ¡£æ£€æŸ¥
        outdated_docs = self.check_outdated_documents(30)
        if outdated_docs:
            report.extend(["## è¿‡æœŸæ–‡æ¡£ (30å¤©æœªæ›´æ–°)\n"])
            for doc_path in outdated_docs:
                version_info = self.versions[doc_path]
                last_modified = version_info.last_modified[:10]
                report.append(
                    f"- {doc_path} (ç‰ˆæœ¬: {version_info.version}, æœ€åæ›´æ–°: {last_modified})"
                )
            report.append("")
        
        # ä¾èµ–å…³ç³»åˆ†æ
        report.extend(["## ä¾èµ–å…³ç³»åˆ†æ\n"])
        dependency_count = 0
        for path, version in self.versions.items():
            if version.dependencies:
                dependency_count += len(version.dependencies)
                report.append(f"- **{path}**: ä¾èµ– {len(version.dependencies)} ä¸ªæ–‡æ¡£")
                for dep in version.dependencies:
                    report.append(f"  - {dep}")
        
        if dependency_count == 0:
            report.append("- æœªå‘ç°æ–‡æ¡£ä¾èµ–å…³ç³»")
        report.append("")
        
        # æ‰€æœ‰æ–‡æ¡£ç‰ˆæœ¬
        report.extend(["## æ‰€æœ‰æ–‡æ¡£ç‰ˆæœ¬\n"])
        sorted_versions = sorted(
            self.versions.items(),
            key=lambda x: x[1].last_modified,
            reverse=True
        )
        
        for file_path, version_info in sorted_versions:
            last_modified = version_info.last_modified[:10]
            git_info = f" ({version_info.git_commit})" if version_info.git_commit else ""
            report.append(f"- **{file_path}**: v{version_info.version} - {last_modified}{git_info}")
        
        return "\n".join(report)
    
    def _is_recent_change(self, timestamp: str, days: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ€è¿‘çš„å˜æ›´"""
        try:
            change_date = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            return change_date > datetime.now() - timedelta(days=days)
        except ValueError:
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ–‡æ¡£ç‰ˆæœ¬ç®¡ç†å·¥å…·')
    parser.add_argument('--project-root', default='.', help='é¡¹ç›®æ ¹ç›®å½•')
    parser.add_argument('--scan', action='store_true', help='æ‰«æå¹¶æ›´æ–°ç‰ˆæœ¬ä¿¡æ¯')
    parser.add_argument('--report', help='ç”Ÿæˆç‰ˆæœ¬æŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶')
    parser.add_argument('--add-headers', action='store_true', help='æ·»åŠ ç‰ˆæœ¬å¤´ä¿¡æ¯')
    parser.add_argument('--cleanup', type=int, help='æ¸…ç†æŒ‡å®šå¤©æ•°å‰çš„å˜æ›´è®°å½•')
    parser.add_argument('--export', help='å¯¼å‡ºç‰ˆæœ¬æ•°æ®åˆ°æŒ‡å®šæ–‡ä»¶')
    parser.add_argument('--check-outdated', type=int, default=30, help='æ£€æŸ¥è¿‡æœŸæ–‡æ¡£çš„å¤©æ•°é˜ˆå€¼')
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºç‰ˆæœ¬ç®¡ç†å™¨
        manager = DocumentVersionManager(args.project_root)
        
        if args.scan:
            print("ğŸ”„ æ›´æ–°æ–‡æ¡£ç‰ˆæœ¬ä¿¡æ¯...")
            changes = manager.update_all_versions()
            
            if changes:
                print(f"ğŸ“ å‘ç° {len(changes)} ä¸ªå˜æ›´")
            else:
                print("âœ… æ²¡æœ‰å‘ç°å˜æ›´")
            
            manager.save_versions()
        
        if args.add_headers:
            print("ğŸ“‹ æ·»åŠ ç‰ˆæœ¬å¤´ä¿¡æ¯...")
            added_count = manager.add_version_headers()
            print(f"âœ… ä¸º {added_count} ä¸ªæ–‡æ¡£æ·»åŠ äº†ç‰ˆæœ¬å¤´ä¿¡æ¯")
            manager.save_versions()
        
        if args.cleanup:
            print(f"ğŸ§¹ æ¸…ç† {args.cleanup} å¤©å‰çš„å˜æ›´è®°å½•...")
            old_count = len(manager.changes)
            
            threshold_date = datetime.now() - timedelta(days=args.cleanup)
            manager.changes = [
                change for change in manager.changes
                if manager._is_recent_change(change.timestamp, args.cleanup)
            ]
            
            new_count = len(manager.changes)
            print(f"âœ… æ¸…ç†äº† {old_count - new_count} æ¡æ—§è®°å½•")
            manager.save_versions()
        
        if args.report:
            print("ğŸ“Š ç”Ÿæˆç‰ˆæœ¬æŠ¥å‘Š...")
            report_content = manager.generate_version_report()
            
            with open(args.report, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.report}")
        
        if args.export:
            print("ğŸ“¤ å¯¼å‡ºç‰ˆæœ¬æ•°æ®...")
            manager.export_version_data(args.export)
            print(f"ğŸ“„ æ•°æ®å·²å¯¼å‡ºåˆ°: {args.export}")
        
        # æ£€æŸ¥è¿‡æœŸæ–‡æ¡£
        outdated_docs = manager.check_outdated_documents(args.check_outdated)
        if outdated_docs:
            print(f"\nâš ï¸ å‘ç° {len(outdated_docs)} ä¸ªè¿‡æœŸæ–‡æ¡£ (è¶…è¿‡ {args.check_outdated} å¤©æœªæ›´æ–°):")
            for doc in outdated_docs:
                version_info = manager.versions[doc]
                last_modified = version_info.last_modified[:10]
                print(f"  - {doc} (ç‰ˆæœ¬: {version_info.version}, æœ€åæ›´æ–°: {last_modified})")
        
        print("âœ… æ–‡æ¡£ç‰ˆæœ¬ç®¡ç†å®Œæˆ")
    
    except Exception as e:
        print(f"âŒ æ–‡æ¡£ç‰ˆæœ¬ç®¡ç†å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()